version: v1.1
Last updated: 2025-05-01

# ⚠️ Limitations of the LoRA Fine-Tuned Model (OpenLLaMA 3B)

This file summarizes known blind spots and challenges from testing the LoRA-fine-tuned version of the OpenLLaMA 3B model on structured prompts for late blight risk classification.

---

## 🚫 Known Issues

### 1. Moderate-Class Confusion
- The model struggles to identify borderline "Moderado" cases.
- Often classifies them as either Low or High depending on temperature more than RH duration.

### 2. Prompt Sensitivity
- The output shifts depending on small wording changes (e.g., “high humidity” vs. “85% humidity”).
- Structured prompts with `Riesgo: <mask>` improved performance but remain sensitive.

### 3. Overconfidence
- Frequently returns one dominant class, often "Bajo," even when inputs are ambiguous.
- Confidence scores are not explicitly expressed by the model.

### 4. RH Duration Handling
- RH is treated as binary (above or below threshold), but the model doesn’t assess multi-day sequences well.
- Cannot distinguish “82% for 6h” from “82% for 2 days” without very specific phrasing.

---

## 🤖 Model Role in the Current GPT

- The LoRA model is **not actively used inside this GPT**.
- This GPT applies expert rules from `rules_late_blight.md` instead.
- However, the limitations above justify building a hybrid fallback system where both models cross-validate.
